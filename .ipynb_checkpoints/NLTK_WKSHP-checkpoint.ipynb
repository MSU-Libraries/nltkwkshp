{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK Workshop \n",
    "Updated March, 2016\n",
    "\n",
    "Introductory code to practice learning Python's Natural Language Toolkit (NLTK), much of which is taken from the excellent [NLTK Book](http://www.nltk.org/book/). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin by importing NLTK along with all the resources used in the NLTK book -- this second part assumes that you have already downloaded the book resources. If you haven't, first enter `nltk.download()` and select the \"book\" resources for download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: Moby Dick by Herman Melville 1851>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260819"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19317"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(text1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text1) / len(set(text1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " 'Moby',\n",
       " 'Dick',\n",
       " 'by',\n",
       " 'Herman',\n",
       " 'Melville',\n",
       " '1851',\n",
       " ']',\n",
       " 'ETYMOLOGY',\n",
       " '.',\n",
       " '(',\n",
       " 'Supplied',\n",
       " 'by',\n",
       " 'a',\n",
       " 'Late',\n",
       " 'Consumptive',\n",
       " 'Usher',\n",
       " 'to',\n",
       " 'a',\n",
       " 'Grammar',\n",
       " 'School',\n",
       " ')',\n",
       " 'The',\n",
       " 'pale',\n",
       " 'Usher']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.tokens[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collocations\n",
    "Find \"collocations\", that is, word combinations that occur more often than would be expected by chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sperm Whale; Moby Dick; White Whale; old man; Captain Ahab; sperm\n",
      "whale; Right Whale; Captain Peleg; New Bedford; Cape Horn; cried Ahab;\n",
      "years ago; lower jaw; never mind; Father Mapple; cried Stubb; chief\n",
      "mate; white whale; ivory leg; one hand\n"
     ]
    }
   ],
   "source": [
    "text1.collocations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more involved approach allows users to make use of additional functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'olive', u'leaf', u'plucked'),\n",
       " (u'rider', u'falls', u'backward'),\n",
       " (u'sewed', u'fig', u'leaves'),\n",
       " (u'yield', u'royal', u'dainties'),\n",
       " (u'during', u'mating', u'season'),\n",
       " (u'Salt', u'Sea', u').'),\n",
       " (u'Sea', u').', u'Twelve'),\n",
       " (u'Their', u'hearts', u'failed'),\n",
       " (u'Valley', u').', u'Melchizedek'),\n",
       " (u'doing', u'forced', u'labor')]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.collocations import *\n",
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "finder = TrigramCollocationFinder.from_words(nltk.corpus.genesis.words('english-web.txt'))\n",
    "finder.nbest(trigram_measures.pmi, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Beer', u'Lahai', u'Roi'),\n",
       " (u'seven', u'ewe', u'lambs'),\n",
       " (u'God', u'Most', u'High'),\n",
       " (u'built', u'an', u'altar'),\n",
       " (u'every', u'living', u'creature'),\n",
       " (u'an', u'everlasting', u'covenant'),\n",
       " (u'every', u'creeping', u'thing'),\n",
       " (u'sixty', u'-', u'five'),\n",
       " (u'soul', u'may', u'bless'),\n",
       " (u'after', u'its', u'kind')]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder.apply_freq_filter(3)\n",
    "finder.nbest(trigram_measures.pmi, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concordances\n",
    "Count words and see them in context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 1226 matches:\n",
      "s , and to teach them by what name a whale - fish is to be called in our tongue\n",
      "t which is not true .\" -- HACKLUYT \" WHALE . ... Sw . and Dan . HVAL . This ani\n",
      "ulted .\" -- WEBSTER ' S DICTIONARY \" WHALE . ... It is more immediately from th\n",
      "ISH . WAL , DUTCH . HWAL , SWEDISH . WHALE , ICELANDIC . WHALE , ENGLISH . BALE\n",
      "HWAL , SWEDISH . WHALE , ICELANDIC . WHALE , ENGLISH . BALEINE , FRENCH . BALLE\n",
      "least , take the higgledy - piggledy whale statements , however authentic , in \n",
      " dreadful gulf of this monster ' s ( whale ' s ) mouth , are immediately lost a\n",
      " patient Job .\" -- RABELAIS . \" This whale ' s liver was two cartloads .\" -- ST\n",
      " Touching that monstrous bulk of the whale or ork we have received nothing cert\n",
      " of oil will be extracted out of one whale .\" -- IBID . \" HISTORY OF LIFE AND D\n",
      "ise .\" -- KING HENRY . \" Very like a whale .\" -- HAMLET . \" Which to secure , n\n",
      "restless paine , Like as the wounded whale to shore flies thro ' the maine .\" -\n",
      ". OF SPERMA CETI AND THE SPERMA CETI WHALE . VIDE HIS V . E . \" Like Spencer ' \n",
      "t had been a sprat in the mouth of a whale .\" -- PILGRIM ' S PROGRESS . \" That \n",
      "EN ' S ANNUS MIRABILIS . \" While the whale is floating at the stern of the ship\n",
      "e ship called The Jonas - in - the - Whale . ... Some say the whale can ' t ope\n",
      " in - the - Whale . ... Some say the whale can ' t open his mouth , but that is\n",
      " masts to see whether they can see a whale , for the first discoverer has a duc\n",
      " for his pains . ... I was told of a whale taken near Shetland , that had above\n",
      "oneers told me that he caught once a whale in Spitzbergen that was white all ov\n",
      "2 , one eighty feet in length of the whale - bone kind came in , which ( as I w\n",
      "n master and kill this Sperma - ceti whale , for I could never hear of any of t\n",
      " . 1729 . \"... and the breath of the whale is frequendy attended with such an i\n",
      "ed with hoops and armed with ribs of whale .\" -- RAPE OF THE LOCK . \" If we com\n",
      "contemptible in the comparison . The whale is doubtless the largest animal in c\n"
     ]
    }
   ],
   "source": [
    "text1.concordance(\"whale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "906"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.count(\"whale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3473673313677301"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import division\n",
    "text1.count(\"whale\") / len(text1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fdist = FreqDist(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FreqDist with 19317 samples and 260819 outcomes>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 18713),\n",
       " ('the', 13721),\n",
       " ('.', 6862),\n",
       " ('of', 6536),\n",
       " ('and', 6024),\n",
       " ('a', 4569),\n",
       " ('to', 4542),\n",
       " (';', 4072),\n",
       " ('in', 3916),\n",
       " ('that', 2982),\n",
       " (\"'\", 2684),\n",
       " ('-', 2552),\n",
       " ('his', 2459),\n",
       " ('it', 2209),\n",
       " ('I', 2124),\n",
       " ('s', 1739),\n",
       " ('is', 1695),\n",
       " ('he', 1661),\n",
       " ('with', 1659),\n",
       " ('was', 1632),\n",
       " ('as', 1620),\n",
       " ('\"', 1478),\n",
       " ('all', 1462),\n",
       " ('for', 1414),\n",
       " ('this', 1280),\n",
       " ('!', 1269),\n",
       " ('at', 1231),\n",
       " ('by', 1137),\n",
       " ('but', 1113),\n",
       " ('not', 1103),\n",
       " ('--', 1070),\n",
       " ('him', 1058),\n",
       " ('from', 1052),\n",
       " ('be', 1030),\n",
       " ('on', 1005),\n",
       " ('so', 918),\n",
       " ('whale', 906),\n",
       " ('one', 889),\n",
       " ('you', 841),\n",
       " ('had', 767),\n",
       " ('have', 760),\n",
       " ('there', 715),\n",
       " ('But', 705),\n",
       " ('or', 697),\n",
       " ('were', 680),\n",
       " ('now', 646),\n",
       " ('which', 640),\n",
       " ('?', 637),\n",
       " ('me', 627),\n",
       " ('like', 624)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist.items()[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FreqDist' object has no attribute 'most_common'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-6b1adc962c02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'FreqDist' object has no attribute 'most_common'"
     ]
    }
   ],
   "source": [
    "fdist.most_common(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering Word Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_words = [w.lower() for w in text1 if w.isalpha()]\n",
    "fdist_words = FreqDist(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 14431),\n",
       " ('of', 6609),\n",
       " ('and', 6430),\n",
       " ('a', 4736),\n",
       " ('to', 4625),\n",
       " ('in', 4172),\n",
       " ('that', 3085),\n",
       " ('his', 2530),\n",
       " ('it', 2522),\n",
       " ('i', 2127),\n",
       " ('he', 1896),\n",
       " ('but', 1818),\n",
       " ('s', 1802),\n",
       " ('as', 1741),\n",
       " ('is', 1725),\n",
       " ('with', 1722),\n",
       " ('was', 1644),\n",
       " ('for', 1617),\n",
       " ('all', 1526),\n",
       " ('this', 1394),\n",
       " ('at', 1319),\n",
       " ('whale', 1226),\n",
       " ('by', 1204),\n",
       " ('not', 1151),\n",
       " ('from', 1088),\n",
       " ('him', 1067),\n",
       " ('so', 1065),\n",
       " ('on', 1062),\n",
       " ('be', 1045),\n",
       " ('one', 921),\n",
       " ('you', 894),\n",
       " ('there', 869),\n",
       " ('now', 785),\n",
       " ('had', 779),\n",
       " ('have', 768),\n",
       " ('or', 713),\n",
       " ('were', 684),\n",
       " ('they', 667),\n",
       " ('which', 648),\n",
       " ('like', 647),\n",
       " ('me', 633),\n",
       " ('then', 630),\n",
       " ('their', 620),\n",
       " ('some', 618),\n",
       " ('what', 618),\n",
       " ('when', 606),\n",
       " ('are', 598),\n",
       " ('an', 596),\n",
       " ('my', 589),\n",
       " ('no', 586)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist_words.items()[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('whale', 1226),\n",
       " ('one', 921),\n",
       " ('like', 647),\n",
       " ('upon', 566),\n",
       " ('man', 527),\n",
       " ('ship', 518),\n",
       " ('ahab', 511),\n",
       " ('ye', 472),\n",
       " ('sea', 455),\n",
       " ('old', 450),\n",
       " ('would', 432),\n",
       " ('though', 384),\n",
       " ('head', 345),\n",
       " ('yet', 345),\n",
       " ('boat', 336),\n",
       " ('time', 334),\n",
       " ('long', 333),\n",
       " ('captain', 329),\n",
       " ('still', 312),\n",
       " ('great', 306),\n",
       " ('said', 304),\n",
       " ('two', 298),\n",
       " ('must', 283),\n",
       " ('seemed', 283),\n",
       " ('white', 281),\n",
       " ('last', 277),\n",
       " ('see', 272),\n",
       " ('thou', 271),\n",
       " ('way', 271),\n",
       " ('whales', 268),\n",
       " ('stubb', 257),\n",
       " ('queequeg', 252),\n",
       " ('little', 249),\n",
       " ('round', 247),\n",
       " ('three', 245),\n",
       " ('men', 244),\n",
       " ('say', 244),\n",
       " ('sperm', 244),\n",
       " ('may', 240),\n",
       " ('first', 235),\n",
       " ('every', 232),\n",
       " ('well', 230),\n",
       " ('us', 228),\n",
       " ('much', 223),\n",
       " ('could', 216),\n",
       " ('good', 216),\n",
       " ('hand', 214),\n",
       " ('side', 208),\n",
       " ('ever', 206),\n",
       " ('never', 206)]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "filtered_words = [w for w in lowercase_words if w not in stopwords.words('english')]\n",
    "fdist_filtered_words = FreqDist(filtered_words)\n",
    "fdist_filtered_words.items()[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hermaphroditical',\n",
       " 'subterraneousness',\n",
       " 'apprehensiveness',\n",
       " 'uninterpenetratingly',\n",
       " 'irresistibleness',\n",
       " 'responsibilities',\n",
       " 'comprehensiveness',\n",
       " 'uncompromisedness',\n",
       " 'superstitiousness',\n",
       " 'uncomfortableness',\n",
       " 'preternaturalness',\n",
       " 'circumnavigating',\n",
       " 'cannibalistically',\n",
       " 'supernaturalness',\n",
       " 'circumnavigations',\n",
       " 'indispensableness',\n",
       " 'simultaneousness',\n",
       " 'undiscriminating',\n",
       " 'characteristically',\n",
       " 'physiognomically',\n",
       " 'indiscriminately',\n",
       " 'circumnavigation']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[word for word in set(filtered_words) if len(word) > 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('unfriendly', 1),\n",
       " ('universally', 4),\n",
       " ('unexpectedly', 1),\n",
       " ('unblinkingly', 1),\n",
       " ('ungentlemanly', 1),\n",
       " ('uninvitedly', 1),\n",
       " ('unrustlingly', 1),\n",
       " ('unmannerly', 2),\n",
       " ('uninterpenetratingly', 1),\n",
       " ('unmanageably', 1),\n",
       " ('unhesitatingly', 1),\n",
       " ('unwittingly', 3),\n",
       " ('unappeasedly', 1),\n",
       " ('unerringly', 3),\n",
       " ('unceasingly', 3),\n",
       " ('unaccountably', 2),\n",
       " ('unspeakably', 2),\n",
       " ('unmistakably', 1),\n",
       " ('unusually', 5),\n",
       " ('unsightly', 1),\n",
       " ('unearthly', 12),\n",
       " ('unreasonably', 2),\n",
       " ('ungainly', 1),\n",
       " ('untraditionally', 1),\n",
       " ('unfathomably', 2),\n",
       " ('untimely', 2),\n",
       " ('unfrequently', 3),\n",
       " ('unsweetly', 1),\n",
       " ('unrestingly', 3),\n",
       " ('unmurmuringly', 1),\n",
       " ('unconditionally', 1),\n",
       " ('unholy', 2),\n",
       " ('unconsciously', 7),\n",
       " ('unduly', 2),\n",
       " ('undoubtedly', 1),\n",
       " ('unthinkingly', 2),\n",
       " ('ungodly', 3),\n",
       " ('unceremoniously', 1),\n",
       " ('unmethodically', 2),\n",
       " ('unwarrantably', 2),\n",
       " ('untrackably', 1),\n",
       " ('unofficially', 1),\n",
       " ('unlikely', 1),\n",
       " ('uniformly', 1),\n",
       " ('unavoidably', 1),\n",
       " ('unprecedentedly', 1),\n",
       " ('unmeaningly', 1),\n",
       " ('uncommonly', 7),\n",
       " ('unbiddenly', 1),\n",
       " ('unnaturally', 1),\n",
       " ('unreluctantly', 1)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "[(word, filtered_words.count(word)) for word in set(filtered_words) if re.search('^un.*ly$', word)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning text to categories algorithmically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('family', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('Dashwood', 'NNP'),\n",
       " ('had', 'VBD'),\n",
       " ('long', 'RB'),\n",
       " ('been', 'VBN'),\n",
       " ('settled', 'VBN'),\n",
       " ('in', 'IN'),\n",
       " ('Sussex', 'NNP'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(sent2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Reference](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html) for part of speech tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[('The', 'AT'), ('Fulton', 'NP-TL'), ('County', 'NN-TL'), ('Grand', 'JJ-TL'), ('Jury', 'NN-TL'), ('said', 'VBD'), ('Friday', 'NR'), ('an', 'AT'), ('investigation', 'NN'), ('of', 'IN'), (\"Atlanta's\", 'NP$'), ('recent', 'JJ'), ('primary', 'NN'), ('election', 'NN'), ('produced', 'VBD'), ('``', '``'), ('no', 'AT'), ('evidence', 'NN'), (\"''\", \"''\"), ('that', 'CS'), ('any', 'DTI'), ('irregularities', 'NNS'), ('took', 'VBD'), ('place', 'NN'), ('.', '.')]], [[('The', 'AT'), ('jury', 'NN'), ('further', 'RBR'), ('said', 'VBD'), ('in', 'IN'), ('term-end', 'NN'), ('presentments', 'NNS'), ('that', 'CS'), ('the', 'AT'), ('City', 'NN-TL'), ('Executive', 'JJ-TL'), ('Committee', 'NN-TL'), (',', ','), ('which', 'WDT'), ('had', 'HVD'), ('over-all', 'JJ'), ('charge', 'NN'), ('of', 'IN'), ('the', 'AT'), ('election', 'NN'), (',', ','), ('``', '``'), ('deserves', 'VBZ'), ('the', 'AT'), ('praise', 'NN'), ('and', 'CC'), ('thanks', 'NNS'), ('of', 'IN'), ('the', 'AT'), ('City', 'NN-TL'), ('of', 'IN-TL'), ('Atlanta', 'NP-TL'), (\"''\", \"''\"), ('for', 'IN'), ('the', 'AT'), ('manner', 'NN'), ('in', 'IN'), ('which', 'WDT'), ('the', 'AT'), ('election', 'NN'), ('was', 'BEDZ'), ('conducted', 'VBN'), ('.', '.')]], ...]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.brown.tagged_paras()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
